---
  title: "STA 325 Case Study"
  author: "Jeff Du, Sahil Tilak"
  header-includes: 
    - \usepackage{float} #use the 'float' package
    - \floatplacement{figure}{H} #make every figure with caption = h
  output: pdf_document
  fontsize: 10pt
  figsintext : yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r libraries, echo=FALSE, warning = FALSE, message = FALSE}
library(dplyr)
library(tidyverse)
library(MASS)
library(patchwork)
library(latex2exp)
library(knitr)
library(kableExtra)
```

```{r read_data, echo = FALSE}
train <- read.csv("data-train.csv")

train$Re <- factor(train$Re)
train$Fr <- factor(train$Fr)
```

# Introduction 

Understanding is one of most challenging problems that physicists face today. This case study will attempt to understand how the relationship between three key properties of particles (Reynolds Number, Stokes Number, and Froud Number) and the probability distribution of particle cluster volumes. 

Through exploratory data analysis and nonlinear regression models, we are able to make predictions about the distribution of particle cluster volumes given parameter settings, as well as understand the way in which each parameter affects the distribution. 

The dataset consists of 7 columns and 89 rows. Each row contains data from a simulation with different 
There are three predictor variables, or parameters:
*Re*: Reynolds Number, which measures the intensity of fluid turbulence of the particle. There are three values of Reynolds Number in the dataset: 90, 224, and 338
*St*: Stokes Number, which measures the size and density of the particle. Stokes Number lies on the interval $[0,3]$ in the dataset
*Fr*: Froud Number, which measures the gravitational acceleration of the particle. There are three values in the dataset: $\infty$, 0.3, and 0.052

There are four predictor variables, which are each of the four moments ($\mathbb{E}[x]$, $\mathbb{E}[x^2]$, $\mathbb{E}[x^3]$, $\mathbb{E}[x^4]$) of the probability distribution function of VoronoÃ¯ volumes, which serve as a measure of the clustering of particles



## EDA

First, we chose to look at the distribution of the four response variables

```{r, echo = FALSE, message = FALSE, warning = FALSE, fig.height = 6, fig.width = 16}
#Response EDA
p1 <- ggplot(aes(x = R_moment_1), data = train)+
  geom_histogram() +
  theme_bw() + 
  labs(x = "E[x]", y = "")

p2 <- ggplot(aes(x = R_moment_2), data = train)+
  geom_histogram() +
  theme_bw() +
  labs(x = TeX("$E[x^{2}]$"), y = "")

p3 <- ggplot(aes(x = R_moment_3), data = train)+
  geom_histogram() +
  theme_bw() +
  labs(x = TeX("$E[x^{3}]$"), y = "")

p4 <- ggplot(aes(x = R_moment_4), data = train)+
  geom_histogram() +
  theme_bw() + 
  labs(x = TeX("$E[x^{4}]$"), y = "")


p1 + p2 + p3 + p4 + plot_layout(widths = c(1.1, 1.2)) + plot_annotation(title = 'Distribution of the Four Moments', theme = theme(plot.title = element_text(hjust = 0.5)))
```

We can see from an histogram of the response variables that all four moments are right skewed and not normally distributed. To account for this, we chose to log-transform the response variables to ensure they are normally distributed.

We also wanted to examine the relationship between the predictors to determine if there is value in including interaction effects. To do so, we plot boxplots to measure the relationship between a continuous and categorical variable (i.e. the relationship between Stokes Number and Reynolds/Froud Number) and a barplot to show the interaction between Reynold's Number and Froud Number

```{r echo = FALSE, warning = FALSE, message = FALSE, fig.height = 6, fig.width = 16}
#predictor EDA

p1 <- ggplot(mapping = aes(x = as.factor(Re), y = log(St)), data = train) +
  geom_boxplot() +
  labs(x = 'Reynolds Number', y = 'Log of Stokes Number')

p2 <- ggplot(mapping = aes(x = as.factor(Fr), y = log(St)), data = train) +
  geom_boxplot() +
  labs(x = 'Froud Number', y = 'Log of Stokes Number')

p3 <- ggplot(mapping = aes(x = as.factor(Re)), data = train) +
  geom_bar(aes(fill = as.factor(Fr))) +
  labs(x = 'Reynolds Number', fill = 'Froud Number')

(p1 + p2) + plot_annotation(title = "Relationship between Predictor Variables", theme = theme(plot.title = element_text(hjust = 0.5)))

```

We notice that there are may be relationships all three combinations of predictor variables, so we will include the interaction effects in our intial model. 

# Methodology

To examine the relationship between a particle's fluid turbulence, gravitational acceleration, and density on the four moments of the cluster
probability distribution, we fit four nonlinear regression models with each
moment as an individual response. We examined through our EDA that the 
four moments are far from normally distributed, and so we considered
a number of transformations on each moment, such as a Box-Cox transformation. Ultimately, we decided to log transform each moment
to have a clear interpretation of our subsequent regression coefficients.
We also log transformed each particle's Stokes number (St) as this predictor was far from normally distributed as well.

Regarding our predictors, we first converted both the Reynolds number and the Froud number of each particle to a categorical predictor, because there only existed three unique values for each predictor in the dataset, and because the numerical differences between such values of Reynolds and Froud numbers was not easily interpretable. We posited from our background research that fitting three interaction, effects for each of the three predictors would better model the relationship
between such predictors. For example, it is well established in existing
research that fluid particle acceleration (Fr) is innately related to the turbulence of a flow (Re), in line with the Kolmogorov microscales.Therefore, we included all three potential interactions in our model (Stokes number interactions are log-transformed).

In terms of increasing our model complexity, we considered using
high order polynomials of log(St) for each of the four moments.
We ran analysis of variance tests fitting different models of varying
degrees of log(St) and found that the quartic fit appeared to be
reasonable for all of the moments. 

Therefore, our general model for each moment is as follows:

$$
\begin{aligned} \quad Y &= \beta_0 + \beta_1log(Stokes) + \beta_2{log(Stokes)^2} + \beta_3{log(Stokes)^3} + \beta_4{log(Stokes)^4} + \beta_5Reynolds \\&\quad + \beta_6Froud + \beta_7(log(Stokes) * Froud) + \beta_8(log(Stokes) * Reynolds) + \beta_9(Froud * Reynolds) + \epsilon \end{aligned}
$$

Finally, we ran both stepwise forward and backward variable selections
on each of our four models using AIC as our criteria. We personally
care less about penalizing more complex models since we are given
so few predictors to begin with anyways. Forward and backward selection
did not remove or add any variables to the second, third, and fourth
moment models, but did remove the interaction term between the Reynolds
Number and the log of the Stokes number for the first moment model. However, we still decided to include this interaction because we believe
it is scientifically grounded.

# Results

```{r, echo=FALSE, results='asis'}
cat("\\twocolumn")
```

Model 1:

```{r model_one, echo = FALSE, warning = FALSE, message = FALSE, fig.width = 7}
firstreg <- lm(log(R_moment_1) ~ poly(log(St), 4) + Re + Fr + log(St) * Fr + log(St) * Re + Fr * Re, data = train)

model_one_df <- as.data.frame(coef(summary(firstreg)))
model_one_df <- model_one_df %>%
  mutate_if(is.numeric, funs(as.character(signif(., 3))))
kable(model_one_df, "latex")
```

Model 2:

```{r model_two , echo = FALSE, warning = FALSE, message = FALSE, fig.width = 7}
secondreg <- lm(log(R_moment_2) ~ poly(log(St), 4) + Re + Fr + log(St) * Fr + log(St) * Re + Fr * Re, data = train)

model_two_df <- as.data.frame(coef(summary(secondreg)))
model_two_df <- model_two_df %>%
  mutate_if(is.numeric, funs(as.character(signif(., 3))))
kable(model_two_df, "latex")
```

Model 3:

```{r model_three, echo = FALSE, warning = FALSE, message = FALSE, fig.width = 7}
thirdreg <- lm(log(R_moment_3) ~ poly(log(St), 4) + Re + Fr + log(St) * Fr + log(St) * Re + Fr * Re, data = train)

model_three_df <- as.data.frame(coef(summary(thirdreg)))
model_three_df <- model_three_df %>%
  mutate_if(is.numeric, funs(as.character(signif(., 3))))
kable(model_three_df, "latex")
```

Model 4:

```{r model_four, echo = FALSE, warning = FALSE, message = FALSE, fig.width = 7}
fourreg <- lm(log(R_moment_4) ~ poly(log(St), 4) + Re + Fr + log(St) * Fr + log(St) * Re + Fr * Re, data = train)

model_four_df <- as.data.frame(coef(summary(fourreg)))
model_four_df <- model_four_df %>%
  mutate_if(is.numeric, funs(as.character(signif(., 3))))
kable(model_four_df, "latex")

```

